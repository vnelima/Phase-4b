{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d142d47",
   "metadata": {},
   "source": [
    "## 1. Building a Pipeline for a Classification Task with Numerical only Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50317311",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbda8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29907da8",
   "metadata": {},
   "source": [
    "### Step 2: Load and Split the Dataset\n",
    "\n",
    "**Load Dataset:** We load the Iris dataset.\n",
    "\n",
    "**Split Dataset:** We split the data into training and test sets using an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40db3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ff007",
   "metadata": {},
   "source": [
    "### Step 3: Define Feature Transformations\n",
    "**Define Features:** We define which features are numerical. For demonstration, we treat all features as numerical.\n",
    "\n",
    "**Create Transformers:**\n",
    "\n",
    "**PCA:** Initialize PCA to reduce the data to 2 principal components.\n",
    "\n",
    "**SelectKBest:** Initialize SelectKBest with ANOVA F-value to select the top 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d7f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features\n",
    "numerical_features = [0, 1, 2, 3]\n",
    "\n",
    "# Create feature transformers\n",
    "pca = PCA(n_components=2)                      # Reduce data to 2 principal components\n",
    "selection = SelectKBest(score_func=f_classif, k=3)  # Select the top 3 features based on ANOVA F-value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57bf9a",
   "metadata": {},
   "source": [
    "### Step 4: Combine Feature Transformations with FeatureUnion\n",
    "**FeatureUnion:** Combine PCA and SelectKBest into a single transformer using FeatureUnion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf2979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FeatureUnion\n",
    "combined_features = FeatureUnion([\n",
    "    ('pca', pca),                              # Apply PCA\n",
    "    ('select', selection)                      # Apply SelectKBest\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e407b75",
   "metadata": {},
   "source": [
    "### Step 5: Apply Transformations to Columns with ColumnTransformer\n",
    "**ColumnTransformer:** Apply the combined transformations to numerical features using ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe177013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', combined_features, numerical_features)   # Apply combined features to numerical data\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9795322",
   "metadata": {},
   "source": [
    "### Step 6: Create and Fit the Pipeline\n",
    "**Pipeline:** Create a pipeline that first preprocesses the data and then applies Logistic Regression.\n",
    "\n",
    "**Fit Pipeline:** Fit the pipeline on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427084b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                                  PCA(n_components=2)),\n",
       "                                                                                 (&#x27;select&#x27;,\n",
       "                                                                                  SelectKBest(k=3))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                                  PCA(n_components=2)),\n",
       "                                                                                 (&#x27;select&#x27;,\n",
       "                                                                                  SelectKBest(k=3))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                 PCA(n_components=2)),\n",
       "                                                                (&#x27;select&#x27;,\n",
       "                                                                 SelectKBest(k=3))]),\n",
       "                                 [0, 1, 2, 3])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2, 3]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>pca</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>select</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=3)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  FeatureUnion(transformer_list=[('pca',\n",
       "                                                                                  PCA(n_components=2)),\n",
       "                                                                                 ('select',\n",
       "                                                                                  SelectKBest(k=3))]),\n",
       "                                                  [0, 1, 2, 3])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),            # Preprocess data\n",
    "    ('classifier', LogisticRegression())       # Classify using Logistic Regression\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2a31a",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the Pipeline\n",
    "**Evaluate Pipeline:** Evaluate the pipeline on the test data by calculating the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8772ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the pipeline on the test data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Test Data Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08051e5",
   "metadata": {},
   "source": [
    "## 2. Building a Pipeline for a Classification Task with Numerical and Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf04cb0",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20e4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957b231",
   "metadata": {},
   "source": [
    "### Step 2: Load and Inspect the Dataset\n",
    "\n",
    "**Load Dataset:** We load the Titanic dataset from OpenML.\n",
    "\n",
    "**Inspect Dataset:**  Display the first few rows of the dataset.\n",
    "**Drop Missing Values:** We drop rows with missing values for simplicity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46dc7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wambu\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                                             name     sex      age  \\\n",
       "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
       "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
       "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
       "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
       "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
       "\n",
       "   sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
       "1    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sample dataset (using Titanic dataset for demonstration)\n",
    "data = fetch_openml(name='titanic', version=1, as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2e328",
   "metadata": {},
   "source": [
    "### Step 3: Drop Rows with Missing Values\n",
    "\n",
    "**Drop Missing Values:** Drop rows with missing values for the specified columns.\n",
    "\n",
    "**Update Target Variable:** Filter y to include only the rows that are still present in X\n",
    "\n",
    "**Split Dataset:** We split the data into training and test sets using an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b61392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for the specified columns\n",
    "X = X.dropna(subset=['age', 'fare', 'embarked', 'sex', 'pclass'])\n",
    "\n",
    "# Update the target variable to match the cleaned feature set\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c246912",
   "metadata": {},
   "source": [
    "### Step 4: Define Feature Transformations\n",
    "**Define Features:** We specify which features are numerical and which are categorical.\n",
    "\n",
    "**Create Transformers for Numerical Data:** We create a pipeline for numerical features that includes scaling, PCA, and feature selection.\n",
    "\n",
    "**Create Transformer for Categorical Data:** We use OneHotEncoder to handle categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b27318d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['age', 'fare']\n",
    "categorical_features = ['sex', 'embarked', 'pclass']\n",
    "\n",
    "# Create feature transformers for numerical data\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('features', FeatureUnion([    # Combine PCA and SelectKBest\n",
    "        ('pca', PCA(n_components=2)), \n",
    "        ('select', SelectKBest(score_func=f_classif, k=2))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Create feature transformer for categorical data\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b005f",
   "metadata": {},
   "source": [
    "### Step 5: Apply Transformations to Columns with ColumnTransformer\n",
    "**ColumnTransformer:** Combine the transformations for numerical and categorical features using ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f6c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, numerical_features),   # Apply numerical transformations\n",
    "    ('cat', cat_transformer, categorical_features)  # Apply categorical transformations\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e848fb0",
   "metadata": {},
   "source": [
    "### Step 6: Create and Fit the Pipeline\n",
    "**Pipeline:** Create a pipeline that first preprocesses the data and then applies Logistic Regression.\n",
    "\n",
    "**Fit Pipeline:** Fit the pipeline on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13573722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  (&#x27;features&#x27;,\n",
       "                                                                   FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                                                   PCA(n_components=2)),\n",
       "                                                                                                  (&#x27;select&#x27;,\n",
       "                                                                                                   SelectKBest(k=2))]))]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;embarked&#x27;,\n",
       "                                                   &#x27;pclass&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  (&#x27;features&#x27;,\n",
       "                                                                   FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                                                   PCA(n_components=2)),\n",
       "                                                                                                  (&#x27;select&#x27;,\n",
       "                                                                                                   SelectKBest(k=2))]))]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;embarked&#x27;,\n",
       "                                                   &#x27;pclass&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                                 (&#x27;features&#x27;,\n",
       "                                                  FeatureUnion(transformer_list=[(&#x27;pca&#x27;,\n",
       "                                                                                  PCA(n_components=2)),\n",
       "                                                                                 (&#x27;select&#x27;,\n",
       "                                                                                  SelectKBest(k=2))]))]),\n",
       "                                 [&#x27;age&#x27;, &#x27;fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                               (&#x27;select&#x27;, SelectKBest(k=2))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>pca</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>select</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=2)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('features',\n",
       "                                                                   FeatureUnion(transformer_list=[('pca',\n",
       "                                                                                                   PCA(n_components=2)),\n",
       "                                                                                                  ('select',\n",
       "                                                                                                   SelectKBest(k=2))]))]),\n",
       "                                                  ['age', 'fare']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['sex', 'embarked',\n",
       "                                                   'pclass'])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),                 # Preprocess data\n",
    "    ('classifier', LogisticRegression())  # Classify using Logistic Regression\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623f81d",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the Pipeline\n",
    "**Evaluate Pipeline:** Evaluate the pipeline on the test data by calculating the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdf95979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 0.7655502392344498\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the pipeline on the test data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Test Data Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ada23f",
   "metadata": {},
   "source": [
    "## 3. Incorporating GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666bba2",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a335dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a25dcc",
   "metadata": {},
   "source": [
    "### Step 2: Load and Inspect the Dataset\n",
    "**Load Dataset:** We load the Titanic dataset from OpenML.\n",
    "\n",
    "**Inspect Dataset:** Display the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d2f163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass                                             name     sex      age  \\\n",
      "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
      "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
      "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
      "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
      "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
      "\n",
      "   sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
      "1    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wambu\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load sample dataset (using Titanic dataset for demonstration)\n",
    "data = fetch_openml(name='titanic', version=1, as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540aa409",
   "metadata": {},
   "source": [
    "## Step 3: Drop Rows with Missing Values\n",
    "**Drop Missing Values:** Drop rows with missing values for the specified columns.\n",
    "\n",
    "**Update Target Variable:** Filter y to include only the rows that are still present in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9931113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for the specified columns\n",
    "X = X.dropna(subset=['age', 'fare', 'embarked', 'sex', 'pclass'])\n",
    "\n",
    "# Update the target variable to match the cleaned feature set\n",
    "y = y.loc[X.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05c2e2",
   "metadata": {},
   "source": [
    "### Step 4: Split the Dataset\n",
    "**Split Dataset:** Split the data into training and test sets using an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2626efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbefdc20",
   "metadata": {},
   "source": [
    "### Step 5: Define Feature Transformations\n",
    "**Define Features:** Specify which features are numerical and which are categorical.\n",
    "\n",
    "**Create Transformers for Numerical Data:** Create a pipeline for numerical features that includes scaling, PCA, and SelectKBest combined using FeatureUnion.\n",
    "\n",
    "**Create Transformer for Categorical Data:** Use OneHotEncoder to handle categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d13dfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = ['age', 'fare']\n",
    "categorical_features = ['sex', 'embarked', 'pclass']\n",
    "\n",
    "# Create feature transformers for numerical data\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('features', FeatureUnion([    # Combine PCA and SelectKBest\n",
    "        ('pca', PCA(n_components=2)), \n",
    "        ('select', SelectKBest(score_func=f_classif, k=2))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Create feature transformer for categorical data\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b50c3",
   "metadata": {},
   "source": [
    "### Step 6: Apply Transformations to Columns with ColumnTransformer\n",
    "**ColumnTransformer:** Combine the transformations for numerical and categorical features using ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d848a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, numerical_features),   # Apply numerical transformations\n",
    "    ('cat', cat_transformer, categorical_features)  # Apply categorical transformations\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68714825",
   "metadata": {},
   "source": [
    "### Step 7: Create the Pipeline\n",
    "**Pipeline:** Create a pipeline that first preprocesses the data and then applies Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aef42331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),                 # Preprocess data\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Classify using Logistic Regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475682f",
   "metadata": {},
   "source": [
    "### Step 8: Define Hyperparameter Grid and Perform GridSearchCV\n",
    "**Parameter Grid:** Define the hyperparameter grid for tuning. This includes parameters for PCA, SelectKBest, and LogisticRegression.\n",
    "\n",
    "**GridSearchCV:** Initialize GridSearchCV with the pipeline and parameter grid, and perform cross-validation.\n",
    "\n",
    "**Fit GridSearchCV:** Fit GridSearchCV to the training data.\n",
    "\n",
    "**Best Parameters and Score:** Print the best parameters and the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b03278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear', 'preprocessor__num__features__pca__n_components': 1, 'preprocessor__num__features__select__k': 1}\n",
      "Best Score: 0.7890123367722387\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocessor__num__features__pca__n_components': [1, 2],           # Tune PCA components\n",
    "    'preprocessor__num__features__select__k': [1, 2],                   # Tune SelectKBest\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],                                # Tune LogisticRegression C\n",
    "    'classifier__penalty': ['l1', 'l2'],                                # Tune LogisticRegression penalty\n",
    "    'classifier__solver': ['liblinear']                                 # Specify solver to handle l1 penalty\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
