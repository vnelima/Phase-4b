{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll explore how to use scikit-learn's `GridSearchCV` class to exhaustively search through every combination of hyperparameters until we find optimal values for a given model.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:\n",
    "\n",
    "- Design a parameter grid for use with scikit-learn's GridSearchCV \n",
    "- Use GridSearchCV to increase model performance through parameter tuning \n",
    "\n",
    "\n",
    "## The dataset\n",
    "\n",
    "For this lab, we'll be working with the [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning dataset repository. We'll be using data about the various features of wine to predict the quality of the wine on a scale from 1-10 stars, making this a multiclass classification problem.  \n",
    "\n",
    "### Getting started\n",
    "\n",
    "Before we can begin grid searching our way to optimal hyperparameters, we'll need to go through the basic steps of modeling. This means that we'll need to:\n",
    "\n",
    "* Import and inspect the dataset (and clean, if necessary)\n",
    "* Split the data into training and test sets\n",
    "* Build and fit a baseline model that we can compare against our grid search results \n",
    "\n",
    "Run the cell below to import everything we'll need for this lab:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported all the necessary libraries and functions for this lab, we'll need to get the dataset.  \n",
    "\n",
    "Our data is stored in the file `'winequality-red.csv'`. Use Pandas to import the data from this file and store it in a DataFrame.  Print the head to ensure that everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's inspect our data. In the cell below, perform some basic exploratory data analysis on our dataset. Get a feel for your data by exploring the descriptive statistics and creating at least one visualization to help you better understand this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a binary column for wine quality\n",
    "df['good_quality'] = df['quality'] >= 7\n",
    "df['good_quality'] = df['good_quality'].astype(int)\n",
    "\n",
    "# Create a histogram to visualize the distribution of wine quality\n",
    "plt.hist(df['quality'], bins=6, color='blue')\n",
    "plt.xlabel('Wine Quality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot to visualize relationships between features\n",
    "#sns.pairplot(df, hue='good_quality', diag_kind='kde')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** Based on your findings during your exploratory data analysis, do you think that we need to do any sort of preprocessing on this dataset? Why or why not?\n",
    "\n",
    "Write your answer below this line:\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "### Preprocessing our data\n",
    "\n",
    "Now, we'll perform any necessary preprocessing on our dataset before training our model. We'll start by isolating the target variable that we are trying to predict.  \n",
    "\n",
    "In the cell below: \n",
    "* Assign the data in the `quality` column to the `y` variable \n",
    "* Drop the `quality` column from the dataset and assign it to `X` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>good_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  good_quality  \n",
       "0      9.4             0  \n",
       "1      9.8             0  \n",
       "2      9.8             0  \n",
       "3      9.8             0  \n",
       "4      9.4             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['quality'] \n",
    "X = df.drop(['quality'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, testing, and cross-validation\n",
    "\n",
    "First we want to do a train-test split to create a holdout set to evaluate how good our final model is. Remember that any time we make modeling decisions based on a section of our data, we risk overfitting to that data. We can make use of **_Cross Validation_** when using `GridSearchCV` to do model selection and hyperparameter tuning, then test our final model choice on the test set.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create a training and test set using `train_test_split()` (set `random_state=42` for reproducability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a baseline model: Decision Trees\n",
    "\n",
    "In the cell below: \n",
    "\n",
    "* Instantiate a `DecisionTreeClassifier`   \n",
    "* Perform a 3-fold cross-validation on the training data using this classifier \n",
    "* Calculate and print the mean cross-validation score from the model \n",
    "\n",
    "**_Note:_** If you need a refresher on how to use `cross_val_score()`, check out the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 70.06%\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_cv_score = cross_val_score(dt_clf, X_train, y_train, cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "\n",
    "print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a second to interpret the results of the cross-validation score.  How well did the model do? How does this compare to a naive baseline level of accuracy (random guessing)?\n",
    "\n",
    "Write your answer below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your answer here\n",
    "'''\n",
    "The model did not perform well, with a mean cross-validation score of 69.23%. \n",
    "This is significantly lower than a naive baseline level of accuracy (random guessing). \n",
    "However, we haven't yet tuned any hyperparameters for this model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search: Decision trees\n",
    "\n",
    "Our model does not have stellar performance. However, we've yet to modify the hyperparameters of the model. Each dataset is different, and the chances that the best possible parameters for a given dataset also happen to be the default parameters set by `scikit-learn` at instantiation is very low.  \n",
    "\n",
    "This means that we need to try **_Hyperparameter Tuning_**.  There are several strategies for searching for optimal hyperparameters. The one we'll be using, **_Combinatoric Grid Searching_**, is probably the most popular because it performs an exhaustive search of all possible combinations.  \n",
    "\n",
    "The sklearn module we'll be using to accomplish this is `GridSearchCV`, which can be found inside of `sklearn.model_selection`.\n",
    "\n",
    "Take a minute to look at sklearn's user guide for [GridSearchCV](http://scikit-learn.org/stable/modules/grid_search.html#grid-search) and then complete the following task.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Complete the `param_grid` dictionary. In this dictionary, each key represents a parameter we want to tune and each corresponding value is a list of every parameter value we'd like to check for that parameter \n",
    "* Normally, you would have to just try different values to search through for each parameter.  However, in order to limit the complexity of this lab, the parameters and values to search through have been provided for you.  You just need to turn them into key-value pairs inside the `param_grid` dictionary. Complete `param_grid` so that it tests the following values for each corresponding parameter:\n",
    "    * For `\"criterion\"`, try values of `\"gini\"` and `\"entropy\"` \n",
    "    * For `\"max_depth\"`, try `None`, as well as 2, 3, 4, 5, and 6  \n",
    "    * For `min_samples_split`, try 2, 5, and 10 \n",
    "    * For `\"min_samples_leaf\"`, try 1, 2, 3, 4, 5, and 6\n",
    "    \n",
    "* Before you run the grid search take some time to understand what each of the specific hyperparameters mean. How does varying the values of each hyperparameter effect the overfitting or underfitting of a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our parameter grid set up, we can use `GridSearchCV`.  Before we do, let's briefly think about the particulars of this model. \n",
    "\n",
    "Grid Search works by training a model on the data for each unique combination of parameters and then returning the parameters of the model that performed best. In order to protect us from randomness, it is common to implement K-Fold cross-validation during this step.  For this lab, we'll set K = 3, meaning that we'll actually train 3 different models for each unique combination of parameters.  \n",
    "\n",
    "Given our `param_grid` and the knowledge that we're going to use 3-fold cross-validation, how many different decision trees will `GridSearchCV` have to train in order to try every possible combination and find the best parameter choices?\n",
    "\n",
    "Calculate and print your answer in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search will have to search through 216 different permutations.\n"
     ]
    }
   ],
   "source": [
    "num_decision_trees = np.prod([len(dt_param_grid[element]) for element in dt_param_grid])\n",
    "\n",
    "print(\n",
    "    f\"Grid Search will have to search through {num_decision_trees} different permutations.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of decision trees! Decision trees are generally pretty quick to train, but that isn't the case with every type of model we want to tune. Be aware that if you set a particularly large search space of parameters inside your parameter grid, then grid search could potentially take a very long time. \n",
    "\n",
    "Let's create our `GridSearchCV` object and fit it. In the cell below: \n",
    "\n",
    "* Instantiate `GridSearchCV`.  Pass in our model, the parameter grid, and `cv=3` to use 3-fold cross-validation. Also set `return_train_score` to `True` \n",
    "* Call our grid search object's `fit()` method and pass in our data and labels, just as if you were using regular cross validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 2, 3, 4, 5, 6],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 2, 3, 4, 5, 6],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             return_train_score=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 3, 4, 5, 6],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV\n",
    "dt_grid_search = GridSearchCV(dt_clf, dt_param_grid, cv=3, return_train_score=True)\n",
    "\n",
    "# Fit to the data\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the best parameters\n",
    "\n",
    "Now that we have fit our model using grid search, we need to inspect it to discover the optimal combination of parameters.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Calculate the the mean training score.  An array of training score results can be found inside the `.cv_results_` dictionary, with the key `mean_train_score` \n",
    "* Calculate the testing score using the our grid search model's `.score()` method by passing in our data and labels  \n",
    "* Examine the appropriate attribute to discover the best estimator parameters found during the grid search  \n",
    "\n",
    "**_HINT:_** If you're unsure what attribute this is stored in, take a look at sklearn's [GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 75.31%\n",
      "Mean Test Score: 67.77%\n",
      "Best Parameter Combination Found During Grid Search: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 6, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "# Mean training score\n",
    "dt_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "dt_gs_testing_score = np.mean(dt_grid_search.cv_results_['mean_test_score'])\n",
    "\n",
    "# Best parameters found during the grid search\n",
    "dt_best_params = dt_grid_search.best_params_\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\", dt_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** What effect, if any, did our parameter tuning have on model performance? Will `GridSearchCV` always discover a perfectly (global) optimal set of parameters? Why or why not?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Your answer here\n",
    "'''\n",
    "Parameter tuning had a positive effect on model performance.\n",
    "The mean cross-validation score improved from 69.23% to 75.31% after tuning the hyperparameters.\n",
    "However, GridSearchCV will not always discover a perfectly (global) optimal set of parameters. \n",
    "This is because GridSearchCV performs an exhaustive search over a specified parameter grid, \n",
    "but the grid itself may not cover all possible parameter values. Additionally, \n",
    "the performance of the model can be influenced by the randomness in the data split and \n",
    "the inherent noise in the dataset. \n",
    "Therefore, while GridSearchCV helps in finding a better set of parameters, \n",
    "it does not guarantee finding the global optimum.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning more advanced models: Random forests\n",
    "\n",
    "Now that we have some experience with grid searching through parameter values for a decision tree classifier, let's try our luck with a more advanced model and tune a _random forest classifier_.  \n",
    "\n",
    "In the cell below:\n",
    "* Instantiate a `RandomForestClassifier` \n",
    "* Use 3-fold cross-validation to generate a baseline score for this model type, so that we have something to compare our tuned model performance to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score for Random Forest Classifier: 75.32%\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "mean_rf_cv_score = np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))\n",
    "\n",
    "print(\n",
    "    f\"Mean Cross Validation Score for Random Forest Classifier: {mean_rf_cv_score :.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our baseline score, we'll create a parameter grid specific to our random forest classifier.  \n",
    "\n",
    "Again -- in a real world situation, you will need to decide what parameters to tune, and be very thoughtful about what values to test for each parameter.  However, since this is a lab, we have provided the following table in the interest of simplicity.  Complete the `rf_param_grid` dictionary with the following key-value pairs:\n",
    " \n",
    " \n",
    " |     Parameter     |         Values         |\n",
    "|:-----------------:|:----------------------:|\n",
    "|    n_estimators   |      [10, 30, 100]     |\n",
    "|     criterion     |   ['gini', 'entropy']  |\n",
    "|     max_depth     | [None, 2, 6, 10] |\n",
    "| min_samples_split |       [5, 10]       |\n",
    "|  min_samples_leaf |   [3, 6]   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = { \n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [3, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have our parameter grid, we can grid search through it with our random forest. \n",
    "\n",
    "In the cell below, follow the process we used with decision trees above to grid search for the best parameters for our random forest classifier.  \n",
    "\n",
    "Instantiate `GridSearchCV` and pass in:\n",
    "* our random forest classifier\n",
    "* the parameter grid \n",
    "* `cv=3` \n",
    "* **_do not_** specify `return_train_score` as we did with our decision trees example above.  In the interest of runtime, we'll only worry about testing accuracy this time  \n",
    "\n",
    "\n",
    "**_NOTE:_** The runtime for the following cell can be over a minute on most computers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 75.23%\n",
      "\n",
      "Optimal Parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Testing Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret results \n",
    "\n",
    "Did tuning the hyperparameters of our random forest classifier improve model performance? Is this performance increase significant? Which model did better? If you had to choose, which model would you put into production? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your answer here\n",
    "'''\n",
    "The performance increase is significant, as the mean cross-validation score for the \n",
    "random forest classifier (74.81%) is higher than the mean cross-validation score for \n",
    "the decision tree classifier (69.23%). \n",
    "This indicates that the random forest classifier is better at generalizing to new, unseen data. \n",
    "The optimal parameters found during the grid search were: {'criterion': 'gini', 'max_depth': None,\n",
    "'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 100}. \n",
    "The classifier performed best with these parameters, achieving a testing accuracy of 74.81%. \n",
    "This is a notable improvement over the untuned random forest classifier. \n",
    "However, as with the decision tree classifier, the grid search may not always find the \n",
    "globally optimal set of parameters. The performance of the model can be influenced by the randomness \n",
    "in the data split and the inherent noise in the dataset. Therefore, while grid search helps in \n",
    "finding a better set of parameters, it does not guarantee finding the global optimum. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performed the best on the holdout set? \n",
    "\n",
    "Run the following cell to see the accuracy of the various grid search models on the test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_score = dt_grid_search.score(X_test, y_test)\n",
    "rf_score = rf_grid_search.score(X_test, y_test)\n",
    "\n",
    "print(\"Decision tree grid search: \", dt_score)\n",
    "print(\"Random forest grid search: \", rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our random forest model performed the best! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned to:\n",
    "\n",
    "* iteratively search for optimal model parameters using `GridSearhCV`\n",
    "* tune model parameters for decision trees and random forests models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
