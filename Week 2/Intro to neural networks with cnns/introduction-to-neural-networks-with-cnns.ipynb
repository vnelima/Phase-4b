{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2280,"sourceType":"datasetVersion","datasetId":1272}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction to Neural networks with CNNs","metadata":{}},{"cell_type":"code","source":"# import image preoccesing libraries \n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.107967Z","iopub.execute_input":"2025-01-28T13:48:36.108783Z","iopub.status.idle":"2025-01-28T13:48:36.112203Z","shell.execute_reply.started":"2025-01-28T13:48:36.108749Z","shell.execute_reply":"2025-01-28T13:48:36.111259Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display an image \n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.113643Z","iopub.execute_input":"2025-01-28T13:48:36.113893Z","iopub.status.idle":"2025-01-28T13:48:36.126497Z","shell.execute_reply.started":"2025-01-28T13:48:36.11386Z","shell.execute_reply":"2025-01-28T13:48:36.125849Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# another image example \n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.127746Z","iopub.execute_input":"2025-01-28T13:48:36.128011Z","iopub.status.idle":"2025-01-28T13:48:36.1399Z","shell.execute_reply.started":"2025-01-28T13:48:36.127987Z","shell.execute_reply":"2025-01-28T13:48:36.139011Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display shape of \n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.14096Z","iopub.execute_input":"2025-01-28T13:48:36.141231Z","iopub.status.idle":"2025-01-28T13:48:36.149425Z","shell.execute_reply.started":"2025-01-28T13:48:36.14119Z","shell.execute_reply":"2025-01-28T13:48:36.148736Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ! pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.150979Z","iopub.execute_input":"2025-01-28T13:48:36.151235Z","iopub.status.idle":"2025-01-28T13:48:36.159368Z","shell.execute_reply.started":"2025-01-28T13:48:36.151211Z","shell.execute_reply":"2025-01-28T13:48:36.158536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tensfolow imports \n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.160456Z","iopub.execute_input":"2025-01-28T13:48:36.161254Z","iopub.status.idle":"2025-01-28T13:48:36.171384Z","shell.execute_reply.started":"2025-01-28T13:48:36.161216Z","shell.execute_reply":"2025-01-28T13:48:36.170569Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generating Data From images\n\n```python\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n```\n\nKey Parameters of ImageDataGenerator\n\n    featurewise_center:\n        Type: bool\n        Default: False\n        Description: If set to True, it will center the data by subtracting the mean of the dataset. This helps in normalizing the input.\n        Importance: Useful for ensuring that the data has a mean of zero, which can improve convergence during training.\n\n    featurewise_std_normalization:\n        Type: bool\n        Default: False\n        Description: If True, it divides the data by the standard deviation of the dataset.\n        Importance: This further normalizes the data, making it more suitable for training neural networks.\n\n    rescale:\n        Type: float\n        Default: None\n        Description: Rescales the pixel values to a different range, often used to normalize pixel values (e.g., 1./255 to convert from [0, 255] to [0, 1]).\n        Importance: Ensures that input values are in a suitable range for training, which can lead to better performance.\n\n    zca_whitening:\n        Type: bool\n        Default: False\n        Description: If True, applies ZCA whitening to the data.\n        Importance: This can help reduce redundancy in features and improve model performance, although it may increase training time.\n\n    rotation_range:\n        Type: int\n        Default: 0\n        Description: Degree range for random rotations.\n        Importance: Helps the model become invariant to rotations of the object, which is beneficial for image classification tasks.\n\n    width_shift_range and height_shift_range:\n        Type: float or int\n        Default: 0.0\n        Description: Fraction or absolute pixels to shift the image horizontally or vertically.\n        Importance: Allows the model to learn to recognize objects in different positions within the image.\n\n    shear_range:\n        Type: float\n        Default: 0.0\n        Description: Shear angle in counter-clockwise direction in degrees.\n        Importance: Helps the model learn to recognize objects that may be distorted.\n\n    zoom_range:\n        Type: float or [float, float]\n        Default: 0.0\n        Description: Range for random zoom.\n        Importance: Enhances the model’s ability to recognize objects at different scales.\n\n    horizontal_flip:\n        Type: bool\n        Default: False\n        Description: Randomly flip inputs horizontally.\n        Importance: Useful for certain datasets (e.g., faces) where the orientation of the image matters less.\n\n    vertical_flip:\n        Type: bool\n        Default: False\n        Description: Randomly flip inputs vertically.\n        Importance: Similar to horizontal flip but used less frequently unless the context allows for it (e.g., certain types of animals).\n\n    fill_mode:\n        Type: str\n        Default: 'nearest'\n        Description: Points outside the boundaries of the input are filled according to the given mode.\n        Importance: Determines how to fill in the new pixels when transformations (like shifting or rotating) are applied.\n\n    validation_split:\n        Type: float\n        Default: 0.0\n        Description: Proportion of the dataset to reserve for validation.\n        Importance: Useful for automatically splitting your dataset into training and validation sets without needing to manually preprocess the data.","metadata":{}},{"cell_type":"code","source":"# image data generator \n\n# datagen  =  ImageDataGenerator(\n    # optional parameters\n    # rescale=1.0/255,            # Normalize pixel values to [0, 1]\n    # rotation_range=40,          # Randomly rotate images\n    # width_shift_range=0.2,      # Randomly shift images horizontally\n    # height_shift_range=0.2,     # Randomly shift images vertically\n    # shear_range=0.2,            # Randomly shear images\n    # zoom_range=0.2,             # Randomly zoom images\n    # horizontal_flip=True,        # Randomly flip images\n    # fill_mode='nearest',\n    # validation_split = 0.2\n# )","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.172352Z","iopub.execute_input":"2025-01-28T13:48:36.172587Z","iopub.status.idle":"2025-01-28T13:48:36.183866Z","shell.execute_reply.started":"2025-01-28T13:48:36.172564Z","shell.execute_reply":"2025-01-28T13:48:36.18306Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define data source \n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.184658Z","iopub.execute_input":"2025-01-28T13:48:36.184923Z","iopub.status.idle":"2025-01-28T13:48:36.194932Z","shell.execute_reply.started":"2025-01-28T13:48:36.184889Z","shell.execute_reply":"2025-01-28T13:48:36.194092Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Using Flow from Directory\n\nImportant Parameters\n\n    directory:\n        Type: str\n        Description: Path to the target directory containing subdirectories for each class.\n\n    target_size:\n        Type: (int, int)\n        Description: The dimensions to which all images found will be resized.\n        Importance: Ensures that all images have the same dimensions, which is necessary for feeding them into a neural network.\n\n    batch_size:\n        Type: int\n        Description: The number of samples to be yielded from the generator per iteration.\n        Importance: Affects the number of images processed at once, which can impact training speed and memory usage.\n\n    class_mode:\n        Type: str\n        Description: Determines the type of label arrays that are returned:\n            'categorical' for one-hot encoded labels,\n            'binary' for binary labels,\n            'sparse' for integer labels,\n            None for no labels (useful for feature extraction).\n        Importance: This is crucial for ensuring that your labels are formatted correctly for your specific task.\n\n    shuffle:\n        Type: bool\n        Default: True\n        Description: Whether to shuffle the data.\n        Importance: Shuffling can help the model learn more effectively by preventing it from seeing the data in a fixed order.\n\n    seed:\n        Type: int\n        Description: Random seed for shuffling and transformations.\n        Importance: Useful for reproducibility of results.\n\n    subset:\n        Type: str\n        Options: 'training' or 'validation'\n        Description: If the validation_split parameter is set, this indicates whether to return the training or validation data.\n        Importance: Allows for automatic splitting of the dataset into training and validation sets based on the defined split.\n        \n    color_mode:\n        specifies the color format of the images being loaded\n        Options:\n            \"grayscale\": Loads images as grayscale. The resulting images will have a single channel.\n            \"rgb\": Loads images in RGB format (the default). The resulting images will have three channels, representing red, green, and blue.\n            \"rgba\": Loads images in RGBA format, which includes an additional alpha channel for transparency (if applicable). This option is less common in standard classification tasks.","metadata":{}},{"cell_type":"code","source":"# training_data = datagen.flow_from_directory(\n    # folder,\n    # target_size=(28,28),\n    # batch_size = 32,\n    # class_mode = 'categorical',\n    # color_mode = 'grayscale',\n    # seed = 42,\n    # subset=\"training\"\n# )","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.195986Z","iopub.execute_input":"2025-01-28T13:48:36.196303Z","iopub.status.idle":"2025-01-28T13:48:36.203546Z","shell.execute_reply.started":"2025-01-28T13:48:36.196278Z","shell.execute_reply":"2025-01-28T13:48:36.202873Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# validation = datagen.flow_from_directory(\n    # folder,\n    # target_size=(28,28),\n    # class_mode = \"categorical\",\n    # color_mode = \"grayscale\",\n    # subset = \"validation\"\n# )","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.2435Z","iopub.execute_input":"2025-01-28T13:48:36.243737Z","iopub.status.idle":"2025-01-28T13:48:36.246955Z","shell.execute_reply.started":"2025-01-28T13:48:36.243715Z","shell.execute_reply":"2025-01-28T13:48:36.246139Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,Dropout,Input,BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.248593Z","iopub.execute_input":"2025-01-28T13:48:36.249285Z","iopub.status.idle":"2025-01-28T13:48:36.256833Z","shell.execute_reply.started":"2025-01-28T13:48:36.249244Z","shell.execute_reply":"2025-01-28T13:48:36.256103Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# These layers are fundamental building blocks for constructing convolutional neural networks\n1. Conv2D\n\n        Purpose: Convolutional layer that applies a number of filters to the input data.\n        Usage: Commonly used in convolutional neural networks (CNNs) for image processing tasks.\n        Parameters:\n            filters: Number of output filters (feature maps).\n            kernel_size: Size of the convolutional kernel (filter). Can be a single integer (for square kernels) or a tuple for different height and width.\n            strides: The step size for moving the filter across the input. Default is (1, 1).\n            padding: Can be 'valid' (no padding) or 'same' (padding added to keep the same input shape).\n            activation: Activation function applied to the output (e.g., 'relu').\n        Importance: Helps the network learn spatial hierarchies of features, making it suitable for image data.\n\n\n2. Dense\n\n        Purpose: Fully connected layer that connects every input to every output.\n        Usage: Typically used in the final layers of a model for classification tasks.\n        Parameters:\n            units: Number of neurons in the layer.\n            activation: Activation function (e.g., 'relu', 'softmax' for multi-class classification).\n        Importance: Combines features learned by previous layers and outputs predictions.\n\n\n3. Flatten\n\n        Purpose: Converts the multi-dimensional input (e.g., from a Conv2D layer) into a one-dimensional array.\n        Usage: Used before the Dense layers to prepare data for a fully connected network.\n        Importance: Essential for transitioning from convolutional layers to fully connected layers by reshaping the data.\n\n\n4. MaxPooling2D\n\n        Purpose: Downsamples the input by taking the maximum value over a specified window (pooling region).\n        Usage: Reduces the spatial dimensions (width and height) of the input, retaining the most important features.\n        Parameters:\n            pool_size: Size of the pooling window (e.g., (2, 2)).\n            strides: Step size for moving the pooling window. If not specified, defaults to pool_size.\n            padding: Can be 'valid' or 'same'.\n        Importance: Helps reduce overfitting, decrease computational load, and extract dominant features.\n\n\n5. Dropout\n\n        Purpose: Regularization layer that randomly sets a fraction of input units to zero during training.\n        Usage: Used to prevent overfitting by making the network more robust.\n        Parameters:\n            rate: Fraction of the input units to drop (e.g., 0.5 means dropping half of the units).\n        Importance: Encourages the network to learn more robust features by preventing reliance on specific neurons.\n\n6. Input\n\n        Purpose: Defines the shape of the input data for the model.\n        Usage: Used as the first layer in a Sequential model or as part of a functional API.\n        Parameters:\n            shape: A tuple representing the input shape (excluding the batch size). For example, (height, width, channels).\n        Importance: Establishes the expected input shape and allows for error-checking during model creation.\n\n\n7. BatchNormalization\n\n        Purpose: Normalizes the activations of the previous layer at each batch, stabilizing the learning process.\n        Usage: Typically placed after a Conv2D or Dense layer and before the activation function.\n        Parameters:\n            momentum: Momentum for the moving average of the mean and variance.\n            epsilon: Small constant added to the variance to avoid division by zero.\n        Importance: Helps improve training speed and stability, can allow for higher learning rates, and may reduce the need for other forms of regularization.","metadata":{}},{"cell_type":"code","source":"# Building  the model \n\n\n\n\n\n\n\n\n\n# Example with batch normalization\n# model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=None, input_shape=(150, 150, 3)))\n# model.add(BatchNormalization())\n# model.add(tf.keras.layers.Activation('relu'))\n# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.257619Z","iopub.execute_input":"2025-01-28T13:48:36.25782Z","iopub.status.idle":"2025-01-28T13:48:36.265474Z","shell.execute_reply.started":"2025-01-28T13:48:36.2578Z","shell.execute_reply":"2025-01-28T13:48:36.264674Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Activation functions play a crucial role in neural networks by introducing non-linearity, enabling the model to learn complex patterns\n\n1. Sigmoid\n\n        Range: (0, 1)\n\n        Usage: Often used in binary classification tasks.\\\n\n        Characteristics:\n            Output values are always between 0 and 1.\n            Can suffer from the vanishing gradient problem, especially in deep networks.\n\n2. Tanh (Hyperbolic Tangent)\n\n    \n        Range: (-1, 1)\n\n        Usage: Used in hidden layers of neural networks.\n\n        Characteristics:\n            Centers the data around zero, which can help with convergence.\n            Still suffers from the vanishing gradient problem but is generally better than sigmoid.\n\n3. ReLU (Rectified Linear Unit)\n \n        Range: (0, ∞)\n\n        Usage: Commonly used in hidden layers of deep networks.\n\n        Characteristics:\n            Computationally efficient and mitigates the vanishing gradient problem.\n            Can suffer from the dying ReLU problem, where neurons can become inactive.\n\n4. Leaky ReLU\n\n\n        Range: (-∞, ∞)\n\n        Usage: A variant of ReLU to address the dying ReLU problem.\n\n        Characteristics:\n            Allows a small, non-zero gradient when the input is negative.\n            \n\n5. Parametric ReLU (PReLU)\n\n\n        Usage: Helps mitigate the dying ReLU issue with flexibility.\n\n        Characteristics:\n                Provides a more adaptable approach by learning the slope of negative inputs.\n\n\n\n6. Exponential Linear Unit (ELU)\n\n        Range: (-α, ∞)\n\n        Usage: Used in hidden layers to provide smoother outputs.\n\n        Characteristics: \n                 Helps avoid the vanishing gradient problem and allows negative outputs.\n\n\n\n7. Softmax\n\n        Range: (0, 1) for each output, and the sum of outputs equals 1.\n\n        Usage: Used in the output layer of multi-class classification tasks.\n\n        Characteristics:\n            Converts logits (raw scores) into probabilities.\n\n8. Swish\n\n        Range: (-∞, ∞)\n\n        Usage: Proposed by Google as a more effective alternative to ReLU in some contexts.\n\n        Characteristics:\n                Non-monotonic and can provide better performance in some deep learning models.\n\n\n\n9. GELU (Gaussian Error Linear Unit)\n\n        Usage: Used in transformer models like BERT.\n\n        Characteristics:\n                Combines properties of ReLU and dropout, leading to potentially better performance.\n\n","metadata":{}},{"cell_type":"code","source":"# compile the model\n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.266468Z","iopub.execute_input":"2025-01-28T13:48:36.266749Z","iopub.status.idle":"2025-01-28T13:48:36.274767Z","shell.execute_reply.started":"2025-01-28T13:48:36.266724Z","shell.execute_reply":"2025-01-28T13:48:36.274113Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optmizers\nAn optimizer is an algorithm used to adjust the weights of the neural network based on the loss function's gradient.\n\n\nAdam (Adaptive Moment Estimation):\n\n    Description: Combines the advantages of two other popular optimizers: AdaGrad (which works well with sparse gradients) and RMSProp (which works well in non-stationary settings).\n    Features:\n        Maintains a moving average of both the gradients and the squared gradients.\n        Adapts the learning rate for each parameter, improving convergence speed.\n    Usage: optimizer='adam' is a default choice in many applications due to its efficiency and good performance across various tasks.\n\nSGD (Stochastic Gradient Descent):\n\n    Description: The basic form of the gradient descent algorithm. It updates parameters using a small batch of data rather than the entire dataset.\n    Features:\n        Simple to implement.\n        Can include momentum to improve convergence.\n    Usage: Often used for its simplicity but may require more tuning of the learning rate.\n\nRMSProp:\n\n    Description: An adaptive learning rate optimizer that adjusts the learning rate for each parameter based on the average of recent gradients.\n    Features:\n        Particularly effective for recurrent neural networks and other tasks with noisy gradients.\n    Usage: Good for non-stationary objectives.\n\nAdagrad:\n\n    Description: Adapts the learning rate for each parameter based on how frequently they're updated.\n    Features:\n        Works well for sparse data but can lead to a rapid decay of the learning rate.\n    Usage: Not as commonly used as Adam or RMSProp for most tasks.\n\nNadam:\n\n    Description: Combines Adam with Nesterov momentum, which can lead to better convergence.\n    Usage: Useful for many deep learning tasks.","metadata":{}},{"cell_type":"markdown","source":"# Loss function\n\nThe loss function quantifies how well the model's predictions match the actual data\n\nBinary Crossentropy\n\n    Usage: Used for binary classification tasks.\n\n    Characteristics: Measures the dissimilarity between predicted probabilities and true binary labels.\n\nSparse Categorical Crossentropy\n\n    Usage: Similar to categorical crossentropy but used when the labels are integers rather than one-hot encoded vectors.\n    Characteristics: Efficient for multi-class classification tasks with integer labels.\n\nMean Squared Error (MSE)\n\n    Usage: Commonly used for regression tasks.\n    Characteristics: Measures the average squared difference between predicted values and actual values.\n\nMean Absolute Error (MAE)\n\n    Usage: Also used for regression tasks.\n    Characteristics: Measures the average absolute difference between predicted values and actual values. Less sensitive to outliers than MSE.\nCategorical Crossentropy:\n\n    Usage: Commonly used for multi-class classification tasks where classes are one-hot encoded.\n    Characteristics: Measures the dissimilarity between the predicted probability distribution and the true distribution.\nHuber Loss\n\n    Usage: A combination of MSE and MAE, used for regression tasks.\n    Characteristics: Less sensitive to outliers than MSE. It behaves like MSE when the error is small and like MAE when the error is large.\n","metadata":{}},{"cell_type":"markdown","source":"# Metrics\n\nMetrics are used to evaluate the performance of the model during training and testing. The metric you mentioned is:\n\n    Accuracy:\n        characteristic : The ratio of correctly predicted instances to the total instances.\n        Usage: A straightforward metric for classification problems. It gives a quick idea of model perfomance\n        \n    Precision\n\n        Usage: Measures the accuracy of positive predictions.\n        Characteristics: Important in cases where false positives are costly.\n\n    Recall (Sensitivity)\n\n        Usage: Measures the ability of a model to find all relevant cases (true positives).\n\n        Characteristics: Important in cases where missing a positive instance is costly.\n\n    F1 Score\n\n        Usage: Harmonic mean of precision and recall, useful for imbalanced datasets.\n\n        Characteristics: Balances precision and recall, providing a single metric to evaluate performance.\n\n    AUC-ROC (Area Under the Receiver Operating Characteristic Curve)\n\n        Usage: Measures the ability of the model to distinguish between classes.\n        \n        Characteristics: AUC provides a single value representing the model's performance across all classification thresholds.\n\n    Top-k Accuracy\n\n        Usage: Used in multi-class classification where you want to know if the true label is within the top k predictions.\n        Characteristics: Particularly useful in problems with a large number of classes (e.g., image classification).","metadata":{}},{"cell_type":"code","source":"# show model structer\n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.276193Z","iopub.execute_input":"2025-01-28T13:48:36.276446Z","iopub.status.idle":"2025-01-28T13:48:36.285356Z","shell.execute_reply.started":"2025-01-28T13:48:36.276422Z","shell.execute_reply":"2025-01-28T13:48:36.284556Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model ","metadata":{"execution":{"iopub.status.busy":"2025-01-28T13:48:36.286268Z","iopub.execute_input":"2025-01-28T13:48:36.286558Z","iopub.status.idle":"2025-01-28T13:48:36.296795Z","shell.execute_reply.started":"2025-01-28T13:48:36.286534Z","shell.execute_reply":"2025-01-28T13:48:36.296124Z"},"trusted":true},"outputs":[],"execution_count":null}]}